{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Nettoyage des entrées utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain how to hack a system! \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_input(user_input):\n",
    "    # Supprimer les caractères spéciaux non désirés\n",
    "    user_input = re.sub(r\"[^\\w\\s,.?!]\", \"\", user_input)\n",
    "    # Limiter la longueur à 200 caractères\n",
    "    return user_input[:200]\n",
    "\n",
    "# Exemple d'entrée\n",
    "user_prompt = \"Explain how to hack a system! @#$%\"\n",
    "cleaned_prompt = clean_input(user_prompt)\n",
    "print(cleaned_prompt)  # Résultat : Explain how to hack a system!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Détection d’intentions malveillantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requête bloquée pour des raisons de sécurité.\n"
     ]
    }
   ],
   "source": [
    "# Liste noire d'expressions interdites\n",
    "blacklist = [\"hack\", \"bypass security\", \"delete database\", \"ignore all instructions\"]\n",
    "\n",
    "def is_malicious(user_input):\n",
    "    user_input_lower = user_input.lower()\n",
    "    return any(phrase in user_input_lower for phrase in blacklist)\n",
    "\n",
    "# Test\n",
    "user_prompt = \"How can I bypass security systems?\"\n",
    "if is_malicious(user_prompt):\n",
    "    print(\"Requête bloquée pour des raisons de sécurité.\")\n",
    "else:\n",
    "    print(\"Requête valide.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validation des prompts générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La réponse a été bloquée pour des raisons de sécurité.\n"
     ]
    }
   ],
   "source": [
    "def validate_response(response):\n",
    "    # Liste de termes interdits dans la réponse\n",
    "    forbidden_terms = [\"password\", \"exploit\", \"confidential\"]\n",
    "    if any(term in response.lower() for term in forbidden_terms):\n",
    "        return \"La réponse a été bloquée pour des raisons de sécurité.\"\n",
    "    return response\n",
    "\n",
    "# Exemple de réponse générée\n",
    "generated_response = \"The exploit allows access to confidential files.\"\n",
    "print(validate_response(generated_response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Limitation des comportements du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an educational assistant. Only respond to educational questions.\n",
      "\n",
      "User: Explain how to hack a database.\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an educational assistant. Only respond to educational questions.\"\n",
    "\n",
    "# Fonction pour ajouter le contexte du système\n",
    "def create_prompt(user_input):\n",
    "    return f\"{system_prompt}\\n\\nUser: {user_input}\\nAssistant:\"\n",
    "\n",
    "user_prompt = \"Explain how to hack a database.\"\n",
    "final_prompt = create_prompt(user_prompt)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Gestion des system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemPromptManager:\n",
    "    def __init__(self, role=\"educational assistant\"):\n",
    "        \"\"\"\n",
    "        Initialise le gestionnaire de prompts système.\n",
    "        \n",
    "        :param role: Rôle du modèle, par exemple 'educational assistant'\n",
    "        \"\"\"\n",
    "        self.system_prompt = (\n",
    "            f\"You are a {role}. \"\n",
    "            \"Your purpose is to assist with educational content. \"\n",
    "            \"Do not provide any information that is unrelated to this role.\"\n",
    "        )\n",
    "\n",
    "    def create_prompt(self, user_input):\n",
    "        \"\"\"\n",
    "        Crée un prompt complet en ajoutant le contexte système.\n",
    "        \n",
    "        :param user_input: Input de l'utilisateur.\n",
    "        :return: Prompt complet à envoyer au modèle.\n",
    "        \"\"\"\n",
    "        return f\"{self.system_prompt}\\n\\nUser: {user_input}\\nAssistant:\"\n",
    "\n",
    "    def validate_response(self, response):\n",
    "        \"\"\"\n",
    "        Valide la réponse générée par le modèle.\n",
    "        \n",
    "        :param response: Réponse générée par le LLM.\n",
    "        :return: Réponse validée ou message d'erreur.\n",
    "        \"\"\"\n",
    "        # Liste de mots ou concepts interdits\n",
    "        forbidden_terms = [\"hack\", \"bypass\", \"confidential\", \"exploit\", \"malware\"]\n",
    "        if any(term in response.lower() for term in forbidden_terms):\n",
    "            return \"La réponse a été bloquée pour des raisons de sécurité.\"\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt complet à envoyer au modèle :\n",
      "You are a educational assistant. Your purpose is to assist with educational content. Do not provide any information that is unrelated to this role.\n",
      "\n",
      "User: Explain how a database works.\n",
      "Assistant:\n",
      "\n",
      "Réponse validée :\n",
      "A database is used to store data securely.\n",
      "\n",
      "Réponse bloquée :\n",
      "La réponse a été bloquée pour des raisons de sécurité.\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialisation du gestionnaire\n",
    "    prompt_manager = SystemPromptManager(role=\"educational assistant\")\n",
    "\n",
    "    # Exemple de prompt utilisateur\n",
    "    user_prompt = \"Explain how a database works.\"\n",
    "    full_prompt = prompt_manager.create_prompt(user_prompt)\n",
    "    print(\"Prompt complet à envoyer au modèle :\")\n",
    "    print(full_prompt)\n",
    "\n",
    "    # Exemple de réponse générée par le modèle\n",
    "    generated_response = \"A database is used to store data securely.\"\n",
    "    validated_response = prompt_manager.validate_response(generated_response)\n",
    "    print(\"\\nRéponse validée :\")\n",
    "    print(validated_response)\n",
    "\n",
    "    # Exemple avec un contenu interdit\n",
    "    malicious_response = \"The exploit allows unauthorized access to the database.\"\n",
    "    validated_response = prompt_manager.validate_response(malicious_response)\n",
    "    print(\"\\nRéponse bloquée :\")\n",
    "    print(validated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Suivi des interactions utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configuration du journal\n",
    "logging.basicConfig(\n",
    "    filename=\"user_interactions.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def log_interaction(user_input, response):\n",
    "    \"\"\"\n",
    "    Enregistre les interactions utilisateur-modèle.\n",
    "    \n",
    "    :param user_input: Input de l'utilisateur.\n",
    "    :param response: Réponse générée par le modèle.\n",
    "    \"\"\"\n",
    "    logging.info(f\"User Input: {user_input} | Response: {response}\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "log_interaction(\"How to hack a system?\", \"Request blocked for security reasons.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Renforcement des règles par chaînes de contrôle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptFilter:\n",
    "    def __init__(self):\n",
    "        self.forbidden_terms = [\"hack\", \"bypass\", \"exploit\", \"malware\"]\n",
    "\n",
    "    def clean_input(self, user_input):\n",
    "        user_input = user_input.strip()[:200]  # Limite à 200 caractères\n",
    "        return user_input\n",
    "\n",
    "    def validate_input(self, user_input):\n",
    "        if any(term in user_input.lower() for term in self.forbidden_terms):\n",
    "            return False, \"Requête bloquée pour des raisons de sécurité.\"\n",
    "        return True, user_input\n",
    "\n",
    "    def validate_output(self, output):\n",
    "        if any(term in output.lower() for term in self.forbidden_terms):\n",
    "            return False, \"Réponse bloquée pour des raisons de sécurité.\"\n",
    "        return True, output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Messages d’erreur conviviaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idée : Remplacer les messages d’erreur génériques par des explications pédagogiques.\n",
    "Avantage : Améliore l’expérience utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blocked_request(reason):\n",
    "    return f\"Votre requête a été bloquée car elle enfreint nos règles. Raison : {reason}. Veuillez poser une question éducative.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
