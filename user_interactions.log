2025-01-29 15:21:50,002 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:21:51,556 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:21:51,560 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:21:53,567 - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-01-29 15:21:55,254 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBvltepWsG9En7B9Hgdr0IjWz9GUrXjB2w "HTTP/1.1 200 OK"
2025-01-29 15:21:55,256 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:21:59,581 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:22:02,681 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:22:02,683 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:22:10,470 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:22:13,510 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:22:13,511 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:25:14,867 - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-01-29 15:25:17,228 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBvltepWsG9En7B9Hgdr0IjWz9GUrXjB2w "HTTP/1.1 200 OK"
2025-01-29 15:25:17,230 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:25:24,699 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:25:26,533 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:25:26,537 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:25:28,241 - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-01-29 15:25:30,034 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBvltepWsG9En7B9Hgdr0IjWz9GUrXjB2w "HTTP/1.1 200 OK"
2025-01-29 15:25:30,036 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:25:35,042 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:25:38,005 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:25:38,008 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:25:53,575 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:25:56,364 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:25:56,365 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:31:15,079 - 
LiteLLM completion() model= ministral-8b-latest; provider = mistral
2025-01-29 15:31:16,946 - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-29 15:31:16,963 - Wrapper: Completed Call, calling success_handler
2025-01-29 15:31:19,000 - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-01-29 15:31:20,371 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBvltepWsG9En7B9Hgdr0IjWz9GUrXjB2w "HTTP/1.1 400 Bad Request"
2025-01-29 15:31:49,677 - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-01-29 15:31:51,150 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBvltepWsG9En7B9Hgdr0IjWz9GUrXjB2w "HTTP/1.1 400 Bad Request"
2025-01-29 15:49:32,427 - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-01-29 15:49:34,242 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBvltepWsG9En7B9Hgdr0IjWz9GUrXjB2w "HTTP/1.1 400 Bad Request"
